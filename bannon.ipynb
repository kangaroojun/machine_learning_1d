{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pandas\n","  Using cached pandas-2.2.2-cp312-cp312-win_amd64.whl.metadata (19 kB)\n","Collecting numpy>=1.26.0 (from pandas)\n","  Using cached numpy-2.0.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n","Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\banno\\onedrive - singapore university of technology and design\\desktop\\machine_learning_1d\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n","Collecting pytz>=2020.1 (from pandas)\n","  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n","Collecting tzdata>=2022.7 (from pandas)\n","  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Requirement already satisfied: six>=1.5 in c:\\users\\banno\\onedrive - singapore university of technology and design\\desktop\\machine_learning_1d\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Using cached pandas-2.2.2-cp312-cp312-win_amd64.whl (11.5 MB)\n","Using cached numpy-2.0.0-cp312-cp312-win_amd64.whl (16.2 MB)\n","Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n","Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n","Installing collected packages: pytz, tzdata, numpy, pandas\n","Successfully installed numpy-2.0.0 pandas-2.2.2 pytz-2024.1 tzdata-2024.1\n"]}],"source":["!pip install pandas"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting scikit-learn\n","  Using cached scikit_learn-1.5.0-cp312-cp312-win_amd64.whl.metadata (11 kB)\n","Requirement already satisfied: numpy>=1.19.5 in c:\\users\\banno\\onedrive - singapore university of technology and design\\desktop\\machine_learning_1d\\.venv\\lib\\site-packages (from scikit-learn) (2.0.0)\n","Collecting scipy>=1.6.0 (from scikit-learn)\n","  Using cached scipy-1.14.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n","Collecting joblib>=1.2.0 (from scikit-learn)\n","  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n","Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n","  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n","Using cached scikit_learn-1.5.0-cp312-cp312-win_amd64.whl (10.9 MB)\n","Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n","Using cached scipy-1.14.0-cp312-cp312-win_amd64.whl (44.5 MB)\n","Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n","Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n","Successfully installed joblib-1.4.2 scikit-learn-1.5.0 scipy-1.14.0 threadpoolctl-3.5.0\n"]}],"source":["!pip install scikit-learn"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","# Load the dataset\n","df = pd.read_csv('./data/train_tfidf_features.csv')\n","\n","df_feature = df.drop('label', axis=1)\n","df_feature = df_feature.drop('id', axis=1)\n","df_target = pd.DataFrame(df['label'])\n"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>4990</th>\n","      <th>4991</th>\n","      <th>4992</th>\n","      <th>4993</th>\n","      <th>4994</th>\n","      <th>4995</th>\n","      <th>4996</th>\n","      <th>4997</th>\n","      <th>4998</th>\n","      <th>4999</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 5000 columns</p>\n","</div>"],"text/plain":["     0    1    2    3    4    5    6    7    8    9  ...  4990  4991  4992  \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n","3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n","4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n","\n","   4993  4994  4995  4996  4997  4998  4999  \n","0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n","1   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n","2   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n","3   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n","4   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n","\n","[5 rows x 5000 columns]"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["df_feature.head()"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   label\n","0      1\n","1      0\n","2      1\n","3      0\n","4      1"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["df_target.head()"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[],"source":["def split_data(df_feature, df_target, random_state=None, test_size=0.5):\n","    indexes = df_feature.index.to_numpy()\n","    if random_state is not None:\n","        np.random.seed(random_state)\n","    test_index = np.random.choice(indexes, int(len(indexes) * test_size), replace=False)\n","    train_index = np.setdiff1d(indexes, test_index)\n","    \n","    df_feature_train = df_feature.loc[train_index, :]\n","    df_feature_test = df_feature.loc[test_index, :]\n","    df_target_train = df_target.loc[train_index, :]\n","    df_target_test = df_target.loc[test_index, :]\n","    \n","    return df_feature_train, df_feature_test, df_target_train, df_target_test\n","\n","def normalize_z(dfin, columns_means=None, columns_stds=None):\n","    if columns_means is None:\n","        columns_means = dfin.mean(axis=0)\n","    if columns_stds is None:\n","        columns_stds = dfin.std(axis=0)\n","    \n","    # Prevent division by zero\n","    columns_stds = columns_stds.replace(0, 1e-5)\n","    \n","    dfout = (dfin - columns_means) / columns_stds\n","    return dfout, columns_means, columns_stds"]},{"cell_type":"markdown","metadata":{},"source":["# Task 3 L"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["PCA Components: 2000, Macro F1 Score: 0.47577897934068236\n","PCA Components: 1000, Macro F1 Score: 0.47165413769915304\n","PCA Components: 500, Macro F1 Score: 0.473529103715535\n","PCA Components: 100, Macro F1 Score: 0.476917766582954\n"]}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.decomposition import PCA\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import f1_score\n","\n","# Load the dataset\n","df = pd.read_csv('./data/train_tfidf_features.csv')\n","\n","# Separate features and labels\n","X = df.drop('label', axis=1)  # Replace 'label_column' with the actual label column name\n","y = df['label']\n","\n","# Split the dataset into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Function to apply PCA\n","def apply_pca(n_components):\n","    pca = PCA(n_components=n_components)\n","    X_train_pca = pca.fit_transform(X_train)\n","    X_test_pca = pca.transform(X_test)\n","    return X_train_pca, X_test_pca\n","\n","# Apply PCA for different component sizes\n","components = [2000, 1000, 500, 100]\n","pca_results = {n: apply_pca(n) for n in components}\n","\n","# Train KNN and evaluate\n","knn = KNeighborsClassifier(n_neighbors=2)\n","\n","def train_and_evaluate(X_train_pca, X_test_pca):\n","    knn.fit(X_train_pca, y_train)\n","    y_pred = knn.predict(X_test_pca)\n","    return y_pred\n","\n","results = {}\n","for n, (X_train_pca, X_test_pca) in pca_results.items():\n","    y_pred = train_and_evaluate(X_train_pca, X_test_pca)\n","    f1 = f1_score(y_test, y_pred, average='macro')\n","    results[n] = f1\n","\n","# Print results\n","for n, f1 in results.items():\n","    print(f\"PCA Components: {n}, Macro F1 Score: {f1}\")\n","\n","# Save predictions for Kaggle submission (example for 100 components)\n","y_pred_100 = train_and_evaluate(*pca_results[100])\n","submission = pd.DataFrame({'Id': X_test.index, 'Prediction': y_pred_100})\n","submission.to_csv('submission_100_components.csv', index=False)\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting xgboost\n","  Downloading xgboost-2.1.0-py3-none-win_amd64.whl.metadata (2.1 kB)\n","Requirement already satisfied: numpy in c:\\users\\banno\\onedrive - singapore university of technology and design\\desktop\\machine_learning_1d\\.venv\\lib\\site-packages (from xgboost) (2.0.0)\n","Requirement already satisfied: scipy in c:\\users\\banno\\onedrive - singapore university of technology and design\\desktop\\machine_learning_1d\\.venv\\lib\\site-packages (from xgboost) (1.14.0)\n","Downloading xgboost-2.1.0-py3-none-win_amd64.whl (124.9 MB)\n","   ---------------------------------------- 0.0/124.9 MB ? eta -:--:--\n","   ---------------------------------------- 0.7/124.9 MB 20.8 MB/s eta 0:00:06\n","    --------------------------------------- 1.8/124.9 MB 23.2 MB/s eta 0:00:06\n","    --------------------------------------- 3.1/124.9 MB 24.6 MB/s eta 0:00:05\n","   - -------------------------------------- 4.2/124.9 MB 24.6 MB/s eta 0:00:05\n","   - -------------------------------------- 5.6/124.9 MB 25.5 MB/s eta 0:00:05\n","   -- ------------------------------------- 6.7/124.9 MB 25.4 MB/s eta 0:00:05\n","   -- ------------------------------------- 8.0/124.9 MB 25.5 MB/s eta 0:00:05\n","   -- ------------------------------------- 9.1/124.9 MB 25.4 MB/s eta 0:00:05\n","   --- ------------------------------------ 9.6/124.9 MB 25.6 MB/s eta 0:00:05\n","   --- ------------------------------------ 9.7/124.9 MB 22.3 MB/s eta 0:00:06\n","   --- ------------------------------------ 9.9/124.9 MB 20.4 MB/s eta 0:00:06\n","   --- ------------------------------------ 10.2/124.9 MB 18.6 MB/s eta 0:00:07\n","   --- ------------------------------------ 11.3/124.9 MB 19.3 MB/s eta 0:00:06\n","   ---- ----------------------------------- 12.6/124.9 MB 19.3 MB/s eta 0:00:06\n","   ---- ----------------------------------- 14.3/124.9 MB 19.8 MB/s eta 0:00:06\n","   ----- ---------------------------------- 15.7/124.9 MB 19.8 MB/s eta 0:00:06\n","   ----- ---------------------------------- 17.2/124.9 MB 20.5 MB/s eta 0:00:06\n","   ------ --------------------------------- 18.9/124.9 MB 21.1 MB/s eta 0:00:06\n","   ------ --------------------------------- 20.6/124.9 MB 32.7 MB/s eta 0:00:04\n","   ------ --------------------------------- 21.5/124.9 MB 32.7 MB/s eta 0:00:04\n","   ------- -------------------------------- 23.7/124.9 MB 34.4 MB/s eta 0:00:03\n","   -------- ------------------------------- 25.4/124.9 MB 34.4 MB/s eta 0:00:03\n","   -------- ------------------------------- 27.3/124.9 MB 36.4 MB/s eta 0:00:03\n","   --------- ------------------------------ 28.9/124.9 MB 36.4 MB/s eta 0:00:03\n","   --------- ------------------------------ 30.6/124.9 MB 36.4 MB/s eta 0:00:03\n","   ---------- ----------------------------- 32.4/124.9 MB 38.5 MB/s eta 0:00:03\n","   ----------- ---------------------------- 34.4/124.9 MB 38.5 MB/s eta 0:00:03\n","   ----------- ---------------------------- 35.9/124.9 MB 38.6 MB/s eta 0:00:03\n","   ----------- ---------------------------- 36.5/124.9 MB 32.8 MB/s eta 0:00:03\n","   ------------ --------------------------- 38.3/124.9 MB 32.8 MB/s eta 0:00:03\n","   ------------ --------------------------- 40.2/124.9 MB 34.4 MB/s eta 0:00:03\n","   ------------- -------------------------- 41.8/124.9 MB 34.4 MB/s eta 0:00:03\n","   ------------- -------------------------- 43.5/124.9 MB 32.7 MB/s eta 0:00:03\n","   -------------- ------------------------- 45.3/124.9 MB 32.7 MB/s eta 0:00:03\n","   --------------- ------------------------ 46.9/124.9 MB 38.5 MB/s eta 0:00:03\n","   --------------- ------------------------ 48.6/124.9 MB 36.4 MB/s eta 0:00:03\n","   ---------------- ----------------------- 50.5/124.9 MB 38.6 MB/s eta 0:00:02\n","   ---------------- ----------------------- 52.3/124.9 MB 38.6 MB/s eta 0:00:02\n","   ----------------- ---------------------- 54.0/124.9 MB 38.5 MB/s eta 0:00:02\n","   ----------------- ---------------------- 55.8/124.9 MB 38.5 MB/s eta 0:00:02\n","   ------------------ --------------------- 57.7/124.9 MB 38.5 MB/s eta 0:00:02\n","   ------------------- -------------------- 59.6/124.9 MB 40.9 MB/s eta 0:00:02\n","   ------------------- -------------------- 61.3/124.9 MB 38.5 MB/s eta 0:00:02\n","   -------------------- ------------------- 63.2/124.9 MB 40.9 MB/s eta 0:00:02\n","   -------------------- ------------------- 65.0/124.9 MB 40.9 MB/s eta 0:00:02\n","   --------------------- ------------------ 66.9/124.9 MB 40.9 MB/s eta 0:00:02\n","   --------------------- ------------------ 68.4/124.9 MB 38.5 MB/s eta 0:00:02\n","   ---------------------- ----------------- 70.3/124.9 MB 38.5 MB/s eta 0:00:02\n","   ----------------------- ---------------- 72.0/124.9 MB 38.5 MB/s eta 0:00:02\n","   ----------------------- ---------------- 73.8/124.9 MB 38.5 MB/s eta 0:00:02\n","   ------------------------ --------------- 75.3/124.9 MB 36.3 MB/s eta 0:00:02\n","   ------------------------ --------------- 76.9/124.9 MB 36.4 MB/s eta 0:00:02\n","   ------------------------- -------------- 78.9/124.9 MB 38.6 MB/s eta 0:00:02\n","   ------------------------- -------------- 80.6/124.9 MB 36.4 MB/s eta 0:00:02\n","   -------------------------- ------------- 82.3/124.9 MB 36.4 MB/s eta 0:00:02\n","   -------------------------- ------------- 84.0/124.9 MB 36.4 MB/s eta 0:00:02\n","   --------------------------- ------------ 85.7/124.9 MB 38.5 MB/s eta 0:00:02\n","   --------------------------- ------------ 87.4/124.9 MB 38.5 MB/s eta 0:00:01\n","   ---------------------------- ----------- 89.0/124.9 MB 36.3 MB/s eta 0:00:01\n","   ----------------------------- ---------- 90.8/124.9 MB 36.4 MB/s eta 0:00:01\n","   ----------------------------- ---------- 92.7/124.9 MB 36.4 MB/s eta 0:00:01\n","   ------------------------------ --------- 94.3/124.9 MB 36.4 MB/s eta 0:00:01\n","   ------------------------------ --------- 96.1/124.9 MB 36.4 MB/s eta 0:00:01\n","   ------------------------------- -------- 97.7/124.9 MB 36.4 MB/s eta 0:00:01\n","   ------------------------------- -------- 99.6/124.9 MB 38.5 MB/s eta 0:00:01\n","   ------------------------------- ------- 101.4/124.9 MB 38.5 MB/s eta 0:00:01\n","   -------------------------------- ------ 103.0/124.9 MB 36.3 MB/s eta 0:00:01\n","   -------------------------------- ------ 105.0/124.9 MB 38.6 MB/s eta 0:00:01\n","   --------------------------------- ----- 106.5/124.9 MB 36.4 MB/s eta 0:00:01\n","   --------------------------------- ----- 108.0/124.9 MB 36.4 MB/s eta 0:00:01\n","   ---------------------------------- ---- 109.6/124.9 MB 36.4 MB/s eta 0:00:01\n","   ---------------------------------- ---- 111.5/124.9 MB 36.4 MB/s eta 0:00:01\n","   ----------------------------------- --- 112.3/124.9 MB 34.4 MB/s eta 0:00:01\n","   ----------------------------------- --- 113.2/124.9 MB 31.2 MB/s eta 0:00:01\n","   ----------------------------------- --- 115.0/124.9 MB 31.1 MB/s eta 0:00:01\n","   ------------------------------------ -- 116.9/124.9 MB 32.8 MB/s eta 0:00:01\n","   ------------------------------------- - 118.7/124.9 MB 32.8 MB/s eta 0:00:01\n","   ------------------------------------- - 120.1/124.9 MB 32.8 MB/s eta 0:00:01\n","   --------------------------------------  122.0/124.9 MB 32.8 MB/s eta 0:00:01\n","   --------------------------------------  123.5/124.9 MB 36.4 MB/s eta 0:00:01\n","   --------------------------------------  124.9/124.9 MB 36.4 MB/s eta 0:00:01\n","   --------------------------------------  124.9/124.9 MB 36.4 MB/s eta 0:00:01\n","   --------------------------------------  124.9/124.9 MB 36.4 MB/s eta 0:00:01\n","   --------------------------------------  124.9/124.9 MB 36.4 MB/s eta 0:00:01\n","   --------------------------------------  124.9/124.9 MB 36.4 MB/s eta 0:00:01\n","   --------------------------------------  124.9/124.9 MB 36.4 MB/s eta 0:00:01\n","   --------------------------------------  124.9/124.9 MB 36.4 MB/s eta 0:00:01\n","   --------------------------------------  124.9/124.9 MB 36.4 MB/s eta 0:00:01\n","   --------------------------------------  124.9/124.9 MB 36.4 MB/s eta 0:00:01\n","   --------------------------------------  124.9/124.9 MB 36.4 MB/s eta 0:00:01\n","   --------------------------------------  124.9/124.9 MB 36.4 MB/s eta 0:00:01\n","   --------------------------------------- 124.9/124.9 MB 12.8 MB/s eta 0:00:00\n","Installing collected packages: xgboost\n","Successfully installed xgboost-2.1.0\n"]}],"source":["!pip install xgboost"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["KNN with PCA Components: 2000, Macro F1 Score: 0.5218488011865823\n","KNN with PCA Components: 1000, Macro F1 Score: 0.5176021928458235\n","KNN with PCA Components: 500, Macro F1 Score: 0.5527413341275035\n","KNN with PCA Components: 100, Macro F1 Score: 0.593241729056758\n","Random Forest Results:\n","PCA Components: 2000, Macro F1 Score: 0.5415740149442299\n","PCA Components: 1000, Macro F1 Score: 0.5640225365950495\n","PCA Components: 500, Macro F1 Score: 0.5892665313150522\n","PCA Components: 100, Macro F1 Score: 0.6091303306873392\n","SVM Results:\n","PCA Components: 2000, Macro F1 Score: 0.6402529331404694\n","PCA Components: 1000, Macro F1 Score: 0.6324128771807379\n","PCA Components: 500, Macro F1 Score: 0.6302789501203805\n","PCA Components: 100, Macro F1 Score: 0.6183301523100327\n","XGBoost Results:\n","PCA Components: 2000, Macro F1 Score: 0.6217998402477325\n","PCA Components: 1000, Macro F1 Score: 0.6394975168822356\n","PCA Components: 500, Macro F1 Score: 0.62840512362262\n","PCA Components: 100, Macro F1 Score: 0.6311885635259854\n"]},{"ename":"AttributeError","evalue":"'numpy.ndarray' object has no attribute 'index'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[11], line 79\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Save best predictions for Kaggle submission (example for 100 components)\u001b[39;00m\n\u001b[0;32m     78\u001b[0m y_pred_100 \u001b[38;5;241m=\u001b[39m best_knn\u001b[38;5;241m.\u001b[39mpredict(pca_results[\u001b[38;5;241m100\u001b[39m][\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m---> 79\u001b[0m submission \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mId\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mX_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrediction\u001b[39m\u001b[38;5;124m'\u001b[39m: y_pred_100})\n\u001b[0;32m     80\u001b[0m submission\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubmission_100_components.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'index'"]}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","from sklearn.metrics import f1_score\n","from xgboost import XGBClassifier\n","\n","# Load the dataset\n","df = pd.read_csv('./data/train_tfidf_features.csv')\n","\n","# Separate features and labels\n","X = df.drop('label', axis=1)  # Replace 'label' with the actual label column name\n","y = df['label']\n","\n","# Split the dataset into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Normalize the data\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# Function to apply PCA\n","def apply_pca(n_components):\n","    pca = PCA(n_components=n_components)\n","    X_train_pca = pca.fit_transform(X_train)\n","    X_test_pca = pca.transform(X_test)\n","    return X_train_pca, X_test_pca\n","\n","# Apply PCA for different component sizes\n","components = [2000, 1000, 500, 100]\n","pca_results = {n: apply_pca(n) for n in components}\n","\n","# Grid search for KNN hyperparameters\n","param_grid = {'n_neighbors': [1, 2, 3, 5, 7, 10]}\n","grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, scoring='f1_macro', cv=5)\n","\n","# Train KNN and evaluate\n","results = {}\n","for n, (X_train_pca, X_test_pca) in pca_results.items():\n","    grid_search.fit(X_train_pca, y_train)\n","    best_knn = grid_search.best_estimator_\n","    y_pred = best_knn.predict(X_test_pca)\n","    f1 = f1_score(y_test, y_pred, average='macro')\n","    results[n] = f1\n","\n","# Print KNN results\n","for n, f1 in results.items():\n","    print(f\"KNN with PCA Components: {n}, Macro F1 Score: {f1}\")\n","\n","# Evaluate with Random Forest, SVM, and XGBoost\n","def evaluate_model(model, X_train_pca, X_test_pca):\n","    model.fit(X_train_pca, y_train) \n","    y_pred = model.predict(X_test_pca)\n","    return f1_score(y_test, y_pred, average='macro')\n","\n","rf_results = {n: evaluate_model(RandomForestClassifier(), X_train_pca, X_test_pca) for n, (X_train_pca, X_test_pca) in pca_results.items()}\n","svm_results = {n: evaluate_model(SVC(), X_train_pca, X_test_pca) for n, (X_train_pca, X_test_pca) in pca_results.items()}\n","xgb_results = {n: evaluate_model(XGBClassifier(), X_train_pca, X_test_pca) for n, (X_train_pca, X_test_pca) in pca_results.items()}\n","\n","# Print results for other models\n","print(\"Random Forest Results:\")\n","for n, f1 in rf_results.items():\n","    print(f\"PCA Components: {n}, Macro F1 Score: {f1}\")\n","\n","print(\"SVM Results:\")\n","for n, f1 in svm_results.items():\n","    print(f\"PCA Components: {n}, Macro F1 Score: {f1}\")\n","\n","print(\"XGBoost Results:\")\n","for n, f1 in xgb_results.items():\n","    print(f\"PCA Components: {n}, Macro F1 Score: {f1}\")\n","\n","# Save best predictions for Kaggle submission (example for 100 components)\n","y_pred_100 = best_knn.predict(pca_results[100][1])\n","submission = pd.DataFrame({'Id': X_test.index, 'Prediction': y_pred_100})\n","submission.to_csv('submission_100_components.csv', index=False)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Logistic Regression Task 1"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","# Load the dataset\n","df = pd.read_csv('./data/train_tfidf_features.csv')\n","\n","df_feature = df.drop('label', axis=1)\n","df_feature = df_feature.drop('id', axis=1)\n","target = pd.DataFrame(df['label'])\n"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>4990</th>\n","      <th>4991</th>\n","      <th>4992</th>\n","      <th>4993</th>\n","      <th>4994</th>\n","      <th>4995</th>\n","      <th>4996</th>\n","      <th>4997</th>\n","      <th>4998</th>\n","      <th>4999</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 5000 columns</p>\n","</div>"],"text/plain":["     0    1    2    3    4    5    6    7    8    9  ...  4990  4991  4992  \\\n","0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n","3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n","4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n","\n","   4993  4994  4995  4996  4997  4998  4999  \n","0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n","1   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n","2   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n","3   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n","4   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n","\n","[5 rows x 5000 columns]"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["df_feature.head()"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   label\n","0      1\n","1      0\n","2      1\n","3      0\n","4      1"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["target.head()"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Iteration 0: Cost 0.6908383573948907, Beta [-1.15761909e-03  1.92035294e-05 -8.05249720e-05  2.22213018e-05\n","  2.93724623e-05]\n","Iteration 100: Cost 0.5424007585248339, Beta [-0.10365702  0.00078116 -0.00655588  0.00174863  0.00219551]\n","Iteration 200: Cost 0.47294474115931523, Beta [-0.18506657  0.00018589 -0.01094772  0.0027942   0.00335115]\n","Iteration 300: Cost 0.4321545291054839, Beta [-0.25140195 -0.000961   -0.01418896  0.00346084  0.00396459]\n","Iteration 400: Cost 0.4048276883917934, Beta [-0.30666288 -0.00229727 -0.01674394  0.00390978  0.00426686]\n","Iteration 500: Cost 0.3849768466777291, Beta [-0.35354844 -0.00365603 -0.01885948  0.00422482  0.00438225]\n","Iteration 600: Cost 0.36975335996353237, Beta [-0.39394475 -0.00496153 -0.02067617  0.00445092  0.00438329]\n","Iteration 700: Cost 0.3576167651733698, Beta [-0.4292121  -0.0061826  -0.02227924  0.00461355  0.00431482]\n","Iteration 800: Cost 0.34765503941402215, Beta [-0.46035752 -0.00731003 -0.02372327  0.00472821  0.00420553]\n","Iteration 900: Cost 0.33929078018234615, Beta [-0.48814288 -0.00834514 -0.02504491  0.00480508  0.00407422]\n","Iteration 1000: Cost 0.33213908346889437, Beta [-0.51315503 -0.00929394 -0.02626981  0.00485134  0.00393331]\n","Iteration 1100: Cost 0.32593263818425106, Beta [-0.53585303 -0.01016411 -0.02741649  0.0048724   0.00379102]\n","Iteration 1200: Cost 0.32047949667419884, Beta [-0.55660075 -0.01096361 -0.02849879  0.00487255  0.00365277]\n","Iteration 1300: Cost 0.31563794231255116, Beta [-0.57569002 -0.01170001 -0.02952726  0.00485529  0.00352203]\n","Iteration 1400: Cost 0.31130085213636066, Beta [-0.5933573  -0.01238017 -0.03051015  0.00482359  0.00340092]\n","Iteration 1500: Cost 0.3073855986347246, Beta [-0.609796   -0.01301022 -0.03145401  0.00477996  0.00329069]\n","Iteration 1600: Cost 0.30382731917492545, Beta [-0.62516568 -0.01359554 -0.03236409  0.00472656  0.00319193]\n","Iteration 1700: Cost 0.3005743061215542, Beta [-0.639599   -0.01414085 -0.0332447   0.00466524  0.0031048 ]\n","Iteration 1800: Cost 0.297584773535733, Beta [-0.65320702 -0.01465029 -0.03409937  0.00459762  0.00302916]\n","Iteration 1900: Cost 0.29482454139991543, Beta [-0.66608343 -0.01512745 -0.03493102  0.00452508  0.00296471]\n","Iteration 2000: Cost 0.29226534583206015, Beta [-0.67830768 -0.0155755  -0.03574211  0.00444882  0.00291099]\n","Iteration 2100: Cost 0.28988358534194186, Beta [-0.68994761 -0.01599721 -0.0365347   0.00436988  0.00286749]\n","Iteration 2200: Cost 0.2876593765223784, Beta [-0.70106145 -0.01639502 -0.0373105   0.00428913  0.00283365]\n","Iteration 2300: Cost 0.2855758330469121, Beta [-0.71169945 -0.01677107 -0.038071    0.00420735  0.00280888]\n","Iteration 2400: Cost 0.2836185082929811, Beta [-0.72190519 -0.01712728 -0.03881744  0.00412518  0.00279264]\n","Iteration 2500: Cost 0.2817749596642983, Beta [-0.73171667 -0.01746533 -0.03955089  0.00404317  0.00278435]\n","Iteration 2600: Cost 0.2800344038830379, Beta [-0.74116715 -0.01778674 -0.04027225  0.00396181  0.00278349]\n","Iteration 2700: Cost 0.2783874427193113, Beta [-0.7502859  -0.01809283 -0.04098233  0.00388148  0.00278955]\n","Iteration 2800: Cost 0.2768258418262599, Beta [-0.75909875 -0.01838483 -0.04168178  0.00380252  0.00280204]\n","Iteration 2900: Cost 0.2753423513517932, Beta [-0.76762864 -0.0186638  -0.0423712   0.00372522  0.00282051]\n","Final Beta: [-0.77581454 -0.01892811 -0.04304434 ... -0.02167527 -0.03465155\n","  0.03996443]\n","Final Cost: 0.27394434157226355\n"]}],"source":["import numpy as np\n","import pandas as pd\n","\n","def split_data(df_feature, df_target, random_state=None, test_size=0.5):\n","    indexes = df_feature.index.to_numpy()\n","    if random_state is not None:\n","        np.random.seed(random_state)\n","    test_index = np.random.choice(indexes, int(len(indexes) * test_size), replace=False)\n","    train_index = np.setdiff1d(indexes, test_index)\n","    \n","    df_feature_train = df_feature.loc[train_index, :]\n","    df_feature_test = df_feature.loc[test_index, :]\n","    df_target_train = df_target.loc[train_index, :]\n","    df_target_test = df_target.loc[test_index, :]\n","    \n","    return df_feature_train, df_feature_test, df_target_train, df_target_test\n","\n","def normalize_z(dfin, columns_means=None, columns_stds=None):\n","    if columns_means is None:\n","        columns_means = dfin.mean(axis=0)\n","    if columns_stds is None:\n","        columns_stds = dfin.std(axis=0)\n","    \n","    # Prevent division by zero\n","    columns_stds = columns_stds.replace(0, 1e-5)\n","    \n","    dfout = (dfin - columns_means) / columns_stds\n","    return dfout, columns_means, columns_stds\n","\n","def prepare_feature(df_feature):\n","    if isinstance(df_feature, pd.DataFrame):\n","        np_feature = df_feature.to_numpy()\n","    else:\n","        np_feature = df_feature\n","    X = np.hstack((np.ones((np_feature.shape[0], 1)), np_feature))\n","    return X\n","\n","def prepare_target(df_target):\n","    if isinstance(df_target, pd.DataFrame):\n","        np_target = df_target.to_numpy()\n","    else:\n","        np_target = df_target\n","    return np_target.ravel()\n","\n","def calc_logreg(X, beta):\n","    z = np.dot(X, beta)\n","    p_x = 1 / (1 + np.exp(-z))\n","    return p_x\n","\n","def compute_cost_linreg(beta, X, y):\n","    epsilon = 1e-5\n","    pred = np.clip(calc_logreg(X, beta), epsilon, 1 - epsilon)\n","    error = np.where(y == 1, np.log(pred), np.log(1 - pred))\n","    J = -np.mean(error)\n","    return J\n","\n","def gradient_descent_logreg(X, y, beta, alpha, num_iters):\n","    m = y.shape[0]\n","    J_storage = np.zeros(num_iters)\n","    for i in range(num_iters):\n","        pred = calc_logreg(X, beta)\n","        error = pred - y\n","        gradient = np.dot(X.T, error) / m\n","        beta -= alpha * gradient\n","        J_storage[i] = compute_cost_linreg(beta, X, y)\n","        \n","        # Debugging: print intermediate values\n","        if i % 100 == 0:\n","            print(f\"Iteration {i}: Cost {J_storage[i]}, Beta {beta[:5]}\")  # Print the first 5 beta values for readability\n","        \n","    return beta, J_storage\n","\n","def predict_norm(X, beta):\n","    probabilities = calc_logreg(X, beta)\n","    return np.where(probabilities >= 0.5, 1, 0)\n","\n","def predict_logreg(df_feature, beta, means=None, stds=None):\n","    df_feature, means, stds = normalize_z(df_feature, means, stds)\n","    X = prepare_feature(df_feature)\n","    return predict_norm(X, beta)\n","\n","# Sample usage:\n","# Assuming df_feature and target are defined\n","df_feature_train, df_feature_test, df_target_train, df_target_test = split_data(df_feature, target, random_state=42, test_size=0.3)\n","\n","df_feature_train_norm, means, stds = normalize_z(df_feature_train)\n","\n","X = prepare_feature(df_feature_train_norm)\n","y = prepare_target(df_target_train)\n","\n","beta = np.zeros(X.shape[1])\n","alpha = 0.01\n","num_iters = 3000\n","beta, J_storage = gradient_descent_logreg(X, y, beta, alpha, num_iters)\n","\n","predictions = predict_logreg(df_feature_test, beta, means, stds)\n","\n","# Print final beta and cost\n","print(f\"Final Beta: {beta}\")\n","print(f\"Final Cost: {J_storage[-1]}\")\n","\n"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"data":{"text/plain":["array([-0.77581454, -0.01892811, -0.04304434, ..., -0.02167527,\n","       -0.03465155,  0.03996443])"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["beta"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[2406  820]\n"," [ 814 1115]]\n"]}],"source":["from sklearn.metrics import confusion_matrix\n","\n","cm = confusion_matrix(df_target_test, predictions)\n","print(cm)"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"data":{"text/plain":["np.float64(0.6618158082210612)"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.metrics import f1_score\n","f1_score(df_target_test, predictions, average='macro')"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"data":{"text/plain":["array([0, 0, 1, ..., 1, 0, 0])"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["df_test_set = pd.read_csv('./data/test_tfidf_features.csv')\n","df_test_set = df_test_set.drop('id', axis=1)\n","predictions = predict_logreg(df_test_set, beta, means, stds)\n","predictions"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["predictions_df = pd.DataFrame(predictions, columns=['label'])\n","test_id = pd.read_csv('./data/test_tfidf_features.csv')['id']\n","submission_df = pd.concat([test_id, predictions_df], axis=1)\n","submission_df.to_csv('LogRed_Prediction.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["---"]},{"cell_type":"markdown","metadata":{},"source":["# Task 2"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.decomposition import PCA\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import f1_score\n","from sklearn.preprocessing import StandardScaler"]},{"cell_type":"markdown","metadata":{},"source":["## PCA and KNearestNeighbours (KNN)"]},{"cell_type":"markdown","metadata":{},"source":["PCA:\n","\n","PCA in sklearn takes in these arguments:\n","\n","1. n_components: int/float\n","    - Number of components to keep. By deafult is all components\n","    \n","https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["df_feature_train, df_feature_test, df_target_train, df_target_test = split_data(df_feature, df_target, random_state=42, test_size=0.3)\n","\n","scaler = StandardScaler()\n","df_feature_train_scaled = scaler.fit_transform(df_feature_train)\n","df_feature_test_scaled = scaler.transform(df_feature_test)"]},{"cell_type":"markdown","metadata":{},"source":["KNN:\n","\n","Most imporatantly, KNeighborsClassifier in sklearn takes in these arguments: \n","1. n_neighours: int\n","    - the number of neighbours that we will be comparing to for us to determine how to classify the identified point\n","2. weights: ['uniform', 'distance']\n","    - uniform: All points in each neighborhood are weighted equally\n","    - distance: Weigh points by the inverse of their distance. --> Closer neighbors of a query point will have greater influence than neighbors which are further away\n","3. metrics: str\n","    - metric to use for distance computation. Default is minkowski\n","\n","https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier\n"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n"]},{"name":"stdout","output_type":"stream","text":["PCA Components: 2000, weight: uniform, metrics: minkowski, Macro F1 Score: 0.5501698573624343\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n"]},{"name":"stdout","output_type":"stream","text":["PCA Components: 2000, weight: uniform, metrics: euclidean, Macro F1 Score: 0.5501698573624343\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n"]},{"name":"stdout","output_type":"stream","text":["PCA Components: 2000, weight: uniform, metrics: manhattan, Macro F1 Score: 0.5524122193964222\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n"]},{"name":"stdout","output_type":"stream","text":["PCA Components: 2000, weight: distance, metrics: minkowski, Macro F1 Score: 0.5392491953449301\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n"]},{"name":"stdout","output_type":"stream","text":["PCA Components: 2000, weight: distance, metrics: euclidean, Macro F1 Score: 0.5392491953449301\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n"]},{"name":"stdout","output_type":"stream","text":["PCA Components: 2000, weight: distance, metrics: manhattan, Macro F1 Score: 0.5435481359602898\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n"]},{"name":"stdout","output_type":"stream","text":["PCA Components: 1000, weight: uniform, metrics: minkowski, Macro F1 Score: 0.5509358763631034\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n"]},{"name":"stdout","output_type":"stream","text":["PCA Components: 1000, weight: uniform, metrics: euclidean, Macro F1 Score: 0.5509358763631034\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n"]},{"name":"stdout","output_type":"stream","text":["PCA Components: 1000, weight: uniform, metrics: manhattan, Macro F1 Score: 0.5508372124746364\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n"]},{"name":"stdout","output_type":"stream","text":["PCA Components: 1000, weight: distance, metrics: minkowski, Macro F1 Score: 0.5501770344051041\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n"]},{"name":"stdout","output_type":"stream","text":["PCA Components: 1000, weight: distance, metrics: euclidean, Macro F1 Score: 0.5501770344051041\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n"]},{"name":"stdout","output_type":"stream","text":["PCA Components: 1000, weight: distance, metrics: manhattan, Macro F1 Score: 0.5495024023827315\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n"]},{"name":"stdout","output_type":"stream","text":["PCA Components: 500, weight: uniform, metrics: minkowski, Macro F1 Score: 0.5537058356694703\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n"]},{"name":"stdout","output_type":"stream","text":["PCA Components: 500, weight: uniform, metrics: euclidean, Macro F1 Score: 0.5537058356694703\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n"]},{"name":"stdout","output_type":"stream","text":["PCA Components: 500, weight: uniform, metrics: manhattan, Macro F1 Score: 0.5517738757177308\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n"]},{"name":"stdout","output_type":"stream","text":["PCA Components: 500, weight: distance, metrics: minkowski, Macro F1 Score: 0.5605568943455942\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n"]},{"name":"stdout","output_type":"stream","text":["PCA Components: 500, weight: distance, metrics: euclidean, Macro F1 Score: 0.5605568943455942\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n"]},{"name":"stdout","output_type":"stream","text":["PCA Components: 500, weight: distance, metrics: manhattan, Macro F1 Score: 0.560207813194894\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n"]},{"name":"stdout","output_type":"stream","text":["PCA Components: 100, weight: uniform, metrics: minkowski, Macro F1 Score: 0.5486275090215184\n","PCA Components: 100, weight: uniform, metrics: euclidean, Macro F1 Score: 0.5486275090215184\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n"]},{"name":"stdout","output_type":"stream","text":["PCA Components: 100, weight: uniform, metrics: manhattan, Macro F1 Score: 0.5452027672093189\n","PCA Components: 100, weight: distance, metrics: minkowski, Macro F1 Score: 0.5817419006772417\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n"]},{"name":"stdout","output_type":"stream","text":["PCA Components: 100, weight: distance, metrics: euclidean, Macro F1 Score: 0.5817419006772417\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n"]},{"name":"stdout","output_type":"stream","text":["PCA Components: 100, weight: distance, metrics: manhattan, Macro F1 Score: 0.5765390074323072\n"]}],"source":["n_components = [2000, 1000, 500, 100]\n","f1_dict = {'uniform, minkowski': [0, 0, 0, 0],\n","           'uniform, euclidean': [0, 0, 0, 0],\n","           'uniform, manhattan': [0, 0, 0, 0],\n","           'distance, minkowski': [0, 0, 0, 0],\n","           'distance, euclidean': [0, 0, 0, 0],\n","           'distance, manhattan': [0, 0, 0, 0]}\n","\n","for i, n in enumerate(n_components):\n","    pca = PCA(n_components=n)\n","    df_feature_train_pca = pca.fit_transform(df_feature_train_scaled)\n","    df_feature_test_pca = pca.transform(df_feature_test_scaled)\n","    \n","    knn = KNeighborsClassifier(n_neighbors=2, weights='uniform', metric='minkowski')\n","    knn.fit(df_feature_train_pca, df_target_train)\n","    y_pred = knn.predict(df_feature_test_pca)\n","    \n","    macro_f1 = f1_score(df_target_test, y_pred, average='macro')\n","    print(f\"PCA Components: {n}, weight: uniform, metrics: minkowski, Macro F1 Score: {macro_f1}\")\n","    f1_dict['uniform, minkowski'][i] = macro_f1\n","    \n","    knn = KNeighborsClassifier(n_neighbors=2, weights='uniform', metric='euclidean')\n","    knn.fit(df_feature_train_pca, df_target_train)\n","    y_pred = knn.predict(df_feature_test_pca)\n","    \n","    macro_f1 = f1_score(df_target_test, y_pred, average='macro')\n","    print(f\"PCA Components: {n}, weight: uniform, metrics: euclidean, Macro F1 Score: {macro_f1}\")\n","    f1_dict['uniform, euclidean'][i] = macro_f1\n","    \n","    knn = KNeighborsClassifier(n_neighbors=2, weights='uniform', metric='manhattan')\n","    knn.fit(df_feature_train_pca, df_target_train)\n","    y_pred = knn.predict(df_feature_test_pca)\n","    \n","    macro_f1 = f1_score(df_target_test, y_pred, average='macro')\n","    print(f\"PCA Components: {n}, weight: uniform, metrics: manhattan, Macro F1 Score: {macro_f1}\")\n","    f1_dict['uniform, manhattan'][i] = macro_f1\n","    \n","    knn = KNeighborsClassifier(n_neighbors=2, weights='distance', metric='minkowski')\n","    knn.fit(df_feature_train_pca, df_target_train)\n","    y_pred = knn.predict(df_feature_test_pca)\n","    \n","    macro_f1 = f1_score(df_target_test, y_pred, average='macro')\n","    print(f\"PCA Components: {n}, weight: distance, metrics: minkowski, Macro F1 Score: {macro_f1}\")\n","    f1_dict['distance, minkowski'][i] = macro_f1\n","    \n","    knn = KNeighborsClassifier(n_neighbors=2, weights='distance', metric='euclidean')\n","    knn.fit(df_feature_train_pca, df_target_train)\n","    y_pred = knn.predict(df_feature_test_pca)\n","    \n","    macro_f1 = f1_score(df_target_test, y_pred, average='macro')\n","    print(f\"PCA Components: {n}, weight: distance, metrics: euclidean, Macro F1 Score: {macro_f1}\")\n","    f1_dict['distance, euclidean'][i] = macro_f1\n","    \n","    knn = KNeighborsClassifier(n_neighbors=2, weights='distance', metric='manhattan')\n","    knn.fit(df_feature_train_pca, df_target_train)\n","    y_pred = knn.predict(df_feature_test_pca)\n","    \n","    macro_f1 = f1_score(df_target_test, y_pred, average='macro')\n","    print(f\"PCA Components: {n}, weight: distance, metrics: manhattan, Macro F1 Score: {macro_f1}\")\n","    f1_dict['distance, manhattan'][i] = macro_f1\n","    # submission = pd.DataFrame({'Id': np.arange(len(y_pred)), 'Predicted': y_pred})\n","    # submission.to_csv(f'./knn_submissions/knn_pca_{n}_components_submission.csv', index=False)\n","    \n","    \n","    \n"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"data":{"text/plain":["{'uniform, minkowski': [np.float64(0.5501698573624343),\n","  np.float64(0.5509358763631034),\n","  np.float64(0.5537058356694703),\n","  np.float64(0.5486275090215184)],\n"," 'uniform, euclidean': [np.float64(0.5501698573624343),\n","  np.float64(0.5509358763631034),\n","  np.float64(0.5537058356694703),\n","  np.float64(0.5486275090215184)],\n"," 'uniform, manhattan': [np.float64(0.5524122193964222),\n","  np.float64(0.5508372124746364),\n","  np.float64(0.5517738757177308),\n","  np.float64(0.5452027672093189)],\n"," 'distance, minkowski': [np.float64(0.5392491953449301),\n","  np.float64(0.5501770344051041),\n","  np.float64(0.5605568943455942),\n","  np.float64(0.5817419006772417)],\n"," 'distance, euclidean': [np.float64(0.5392491953449301),\n","  np.float64(0.5501770344051041),\n","  np.float64(0.5605568943455942),\n","  np.float64(0.5817419006772417)],\n"," 'distance, manhattan': [np.float64(0.5435481359602898),\n","  np.float64(0.5495024023827315),\n","  np.float64(0.560207813194894),\n","  np.float64(0.5765390074323072)]}"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["f1_dict"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n","c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:238: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  return self._fit(X, y)\n"]},{"name":"stdout","output_type":"stream","text":["Macro F1 score with 2000 components: 0.5427743603294302\n","Best parameters with 2000 components: {'metric': 'euclidean', 'n_neighbors': 2, 'weights': 'distance'}\n","Macro F1 score with 1000 components: 0.5450593232052263\n","Best parameters with 1000 components: {'metric': 'euclidean', 'n_neighbors': 2, 'weights': 'distance'}\n","Macro F1 score with 500 components: 0.5499751045702174\n","Best parameters with 500 components: {'metric': 'manhattan', 'n_neighbors': 2, 'weights': 'distance'}\n","Macro F1 score with 100 components: 0.5747690063350932\n","Best parameters with 100 components: {'metric': 'manhattan', 'n_neighbors': 2, 'weights': 'distance'}\n"]}],"source":["from sklearn.model_selection import GridSearchCV, cross_val_score\n","\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(df_feature_train)\n","X_test_scaled = scaler.transform(df_feature_test)\n","\n","# Function to perform PCA and KNN, and return the Macro F1 score\n","def pca_knn(X_train, y_train, X_test, y_test, n_components):\n","    pca = PCA(n_components=n_components)\n","    X_train_pca = pca.fit_transform(X_train)\n","    X_test_pca = pca.transform(X_test)\n","    \n","    knn = KNeighborsClassifier(n_neighbors=2)\n","    knn.fit(X_train_pca, y_train)\n","    y_pred = knn.predict(X_test_pca)\n","    \n","    macro_f1 = f1_score(y_test, y_pred, average='macro')\n","    return macro_f1, y_pred\n","\n","# Function to perform hyperparameter tuning and cross-validation\n","def tune_knn(X_train, y_train, X_test, y_test, n_components):\n","    pca = PCA(n_components=n_components)\n","    X_train_pca = pca.fit_transform(X_train)\n","    X_test_pca = pca.transform(X_test)\n","    \n","    # Define parameter grid\n","    param_grid = {\n","        'n_neighbors': [2],\n","        'weights': ['uniform', 'distance'],\n","        'metric': ['euclidean', 'minkowski' , 'manhattan']\n","    }\n","    \n","    knn = KNeighborsClassifier()\n","    grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='f1_macro')\n","    grid_search.fit(X_train_pca, y_train)\n","    \n","    best_knn = grid_search.best_estimator_\n","    y_pred = best_knn.predict(X_test_pca)\n","    \n","    macro_f1 = f1_score(y_test, y_pred, average='macro')\n","    return macro_f1, y_pred, grid_search.best_params_\n","\n","# Number of components to try\n","components_list = [2000, 1000, 500, 100]\n","macro_f1_scores = {}\n","best_params = {}\n","predictions = {}\n","\n","for n_components in components_list:\n","    macro_f1, y_pred, best_params_for_config = tune_knn(X_train_scaled, df_target_train, X_test_scaled, df_target_test, n_components)\n","    macro_f1_scores[n_components] = macro_f1\n","    best_params[n_components] = best_params_for_config\n","    predictions[n_components] = y_pred\n","\n","# Print the Macro F1 scores and best parameters\n","for n_components in components_list:\n","    print(f\"Macro F1 score with {n_components} components: {macro_f1_scores[n_components]}\")\n","    print(f\"Best parameters with {n_components} components: {best_params[n_components]}\")\n","\n","# Save predictions for Kaggle submission\n","for n_components, y_pred in predictions.items():\n","    submission = pd.DataFrame({'Id': np.arange(len(y_pred)), 'Predicted': y_pred})\n","    submission.to_csv(f'./knn_true/knn_pca_{n_components}_components_submission.csv', index=False)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":["{2000: {'metric': 'euclidean', 'n_neighbors': 2, 'weights': 'distance'},\n"," 1000: {'metric': 'euclidean', 'n_neighbors': 2, 'weights': 'distance'},\n"," 500: {'metric': 'manhattan', 'n_neighbors': 2, 'weights': 'distance'},\n"," 100: {'metric': 'manhattan', 'n_neighbors': 2, 'weights': 'distance'}}"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["macro_f1_scores\n","best_params\n","# predictions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# Task 3"]},{"cell_type":"markdown","metadata":{},"source":["## GridSearchCV"]},{"cell_type":"markdown","metadata":{},"source":["sklearn.model_selection.GridSearchCV(estimator, param_grid, scoring=None, n_jobs=None, refit=True, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n","\n","1. estimator: estimator object\n","    - Machine learning model from sklearn that you set to a variable\n","2. param_grid: dictionary or list of dictionaries\n","    - dictionary with parameter names as keys and lists of parameter settings to try as values\n","    - a list of such dictionaries in which case the grids spanned by each dictionary in the list are explored\n","3. scoring: str\n","    - single string to represent the scorer\n","    - a list or tuple of unique strings for multiple scorers\n","4. n_jobs: int\n","    - default = None\n","    - number of jobs to run in parallel\n","5. cv: int\n","    - default = None\n","    - determines the cross-validation splitting strategy\n","    - integer represents number of folds\n","\n","Attributes:\n","\n","1. gridsearch.best_estimator_\n","    - estimator that gives the highest score\n","    - it is the model with the params that give the best results\n","2. gridsearch.best_score_\n","    - mean cross-validated \n","3. gridsearch.best_params_\n","    - returns a dictionary of the best params that make up the best estimator\n","\n","Functions:\n","1. .fit(X, y=None, **params)\n","    - X: array-like of shape (n_samples, n_features)\n","    - y: array-like of shape (n_samples, n_features) or (n_samples, ), default = None\n","    - **params: dictonary of string\n","        * idk what it does so not important??\n","2. .predict(X)\n","    - X: indexable, length of n_samples\n","    - returns y_pred: ndarray of shape (n_samples)"]},{"cell_type":"markdown","metadata":{},"source":["## Standard Vector Machine (SVM)"]},{"cell_type":"markdown","metadata":{},"source":["SVC:\n","\n","sklearn.svm.SVC():\n","\n","1. C: float\n","    - regularization parameter\n","    - default = 1.0\n","    - strength of the regularization is inversely proportional to C\n","2. kernal\n","    - kernal to be used\n","    - default is 'rbf'\n","3. degree: int\n","    - default = 3\n","    - degree of the polynomal kernal function\n","4. random_state: int\n","    - deafult = None\n","    - controls the pseudo random number generator for shuffling data"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["from sklearn.svm import SVC\n","from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n","\n","df_feature_train, df_feature_test, df_target_train, df_target_test = split_data(df_feature, target, random_state=42, test_size=0.3)\n","scalar = StandardScaler()\n","df_feature_train_scaled = scalar.fit_transform(df_feature_train)\n","df_feature_test_scaled = scalar.transform(df_feature_test)\n","\n","# Initialize the SVM model\n","svm = SVC(kernel='linear', C=1, random_state=42)"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1310: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]}],"source":["# Train the model\n","svm.fit(df_feature_train_scaled, df_target_train)\n","\n","# Make predictions\n","y_pred = svm.predict(df_feature_test_scaled)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n","print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n","print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"]},{"cell_type":"markdown","metadata":{},"source":["## XGBoost"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: xgboost in c:\\users\\banno\\onedrive - singapore university of technology and design\\desktop\\machine_learning_1d\\.venv\\lib\\site-packages (2.1.0)\n","Requirement already satisfied: numpy in c:\\users\\banno\\onedrive - singapore university of technology and design\\desktop\\machine_learning_1d\\.venv\\lib\\site-packages (from xgboost) (2.0.0)\n","Requirement already satisfied: scipy in c:\\users\\banno\\onedrive - singapore university of technology and design\\desktop\\machine_learning_1d\\.venv\\lib\\site-packages (from xgboost) (1.14.0)\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 24.1.1 -> 24.1.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["!pip install xgboost"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["import xgboost as XGBClassifier\n","from sklearn.preprocessing import StandardScaler\n","\n","df_feature_train, df_feature_test, df_target_train, df_target_test = split_data(df_feature, df_target, random_state=42, test_size=0.3)\n","scalar = StandardScaler()\n","df_feature_train_scaled = scalar.fit_transform(df_feature_train)\n","df_feature_test_scaled = scalar.transform(df_feature_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = XGBClassifier(objective='binary:logistic', learning_rate=0.1, n_estimators=100, max_depth=5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["bst = XGBClassifier(n_estimators=2, max_depth=2, learning_rate=1, objective='binary:logistic')\n","# fit model\n","bst.fit(X_train, y_train)\n","# make predictions\n","preds = bst.predict(X_test)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 3 folds for each of 80 candidates, totalling 240 fits\n","[CV] END classifier__max_depth=3, classifier__n_estimators=50, pca__n_components=2000; total time=  20.8s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=50, pca__n_components=2000; total time=  25.9s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=50, pca__n_components=2000; total time=  25.8s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=50, pca__n_components=1000; total time=   9.4s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=50, pca__n_components=1000; total time=  10.5s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=50, pca__n_components=1000; total time=  10.2s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=50, pca__n_components=500; total time=   4.7s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=50, pca__n_components=500; total time=   7.0s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=50, pca__n_components=500; total time=   4.6s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=50, pca__n_components=100; total time=   1.8s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=50, pca__n_components=100; total time=   1.8s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=50, pca__n_components=100; total time=   1.8s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=100, pca__n_components=2000; total time=  24.3s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=100, pca__n_components=2000; total time=  24.9s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=100, pca__n_components=2000; total time=  24.5s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=100, pca__n_components=1000; total time=  11.1s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=100, pca__n_components=1000; total time=  11.2s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=100, pca__n_components=1000; total time=  11.8s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=100, pca__n_components=500; total time=   5.4s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=100, pca__n_components=500; total time=   5.4s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=100, pca__n_components=500; total time=   5.4s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=100, pca__n_components=100; total time=   1.8s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=100, pca__n_components=100; total time=   1.9s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=100, pca__n_components=100; total time=   1.8s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=200, pca__n_components=2000; total time=  31.4s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=200, pca__n_components=2000; total time=  30.8s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=200, pca__n_components=2000; total time=  38.7s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=200, pca__n_components=1000; total time=  15.6s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=200, pca__n_components=1000; total time=  14.4s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=200, pca__n_components=1000; total time=  14.3s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=200, pca__n_components=500; total time=   6.9s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=200, pca__n_components=500; total time=   6.8s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=200, pca__n_components=500; total time=   7.4s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=200, pca__n_components=100; total time=   2.0s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=200, pca__n_components=100; total time=   2.0s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=200, pca__n_components=100; total time=   2.0s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=300, pca__n_components=2000; total time=  37.7s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=300, pca__n_components=2000; total time=  37.3s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=300, pca__n_components=2000; total time=  38.8s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=300, pca__n_components=1000; total time=  17.8s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=300, pca__n_components=1000; total time=  17.7s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=300, pca__n_components=1000; total time=  17.5s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=300, pca__n_components=500; total time=   8.5s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=300, pca__n_components=500; total time=   8.4s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=300, pca__n_components=500; total time=   8.4s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=300, pca__n_components=100; total time=   2.2s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=300, pca__n_components=100; total time=   2.1s\n","[CV] END classifier__max_depth=3, classifier__n_estimators=300, pca__n_components=100; total time=   2.1s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=50, pca__n_components=2000; total time=  22.0s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=50, pca__n_components=2000; total time=  22.1s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=50, pca__n_components=2000; total time=  22.7s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=50, pca__n_components=1000; total time=   9.9s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=50, pca__n_components=1000; total time=  10.1s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=50, pca__n_components=1000; total time=  10.0s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=50, pca__n_components=500; total time=   4.8s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=50, pca__n_components=500; total time=   4.9s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=50, pca__n_components=500; total time=   4.9s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=50, pca__n_components=100; total time=   1.9s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=50, pca__n_components=100; total time=   1.8s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=50, pca__n_components=100; total time=   1.8s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=100, pca__n_components=2000; total time=  28.5s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=100, pca__n_components=2000; total time=  26.9s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=100, pca__n_components=2000; total time=  29.8s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=100, pca__n_components=1000; total time=  12.4s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=100, pca__n_components=1000; total time=  12.4s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=100, pca__n_components=1000; total time=  12.5s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=100, pca__n_components=500; total time=   6.8s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=100, pca__n_components=500; total time=   8.2s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=100, pca__n_components=500; total time=   6.1s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=100, pca__n_components=100; total time=   2.0s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=100, pca__n_components=100; total time=   2.0s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=100, pca__n_components=100; total time=   1.9s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=200, pca__n_components=2000; total time=  41.6s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=200, pca__n_components=2000; total time=  36.5s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=200, pca__n_components=2000; total time=  38.9s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=200, pca__n_components=1000; total time=  17.1s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=200, pca__n_components=1000; total time=  17.6s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=200, pca__n_components=1000; total time=  17.4s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=200, pca__n_components=500; total time=   8.3s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=200, pca__n_components=500; total time=   8.5s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=200, pca__n_components=500; total time=   8.2s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=200, pca__n_components=100; total time=   2.2s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=200, pca__n_components=100; total time=   2.2s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=200, pca__n_components=100; total time=   2.1s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=300, pca__n_components=2000; total time=  46.7s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=300, pca__n_components=2000; total time=  46.6s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=300, pca__n_components=2000; total time=  47.0s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=300, pca__n_components=1000; total time=  22.0s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=300, pca__n_components=1000; total time=  24.4s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=300, pca__n_components=1000; total time=  22.1s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=300, pca__n_components=500; total time=  10.6s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=300, pca__n_components=500; total time=  10.6s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=300, pca__n_components=500; total time=  10.4s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=300, pca__n_components=100; total time=   2.4s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=300, pca__n_components=100; total time=   2.4s\n","[CV] END classifier__max_depth=4, classifier__n_estimators=300, pca__n_components=100; total time=   2.4s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=50, pca__n_components=2000; total time=  24.3s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=50, pca__n_components=2000; total time=  24.5s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=50, pca__n_components=2000; total time=  24.3s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=50, pca__n_components=1000; total time=  11.1s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=50, pca__n_components=1000; total time=  11.0s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=50, pca__n_components=1000; total time=  11.2s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=50, pca__n_components=500; total time=   5.3s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=50, pca__n_components=500; total time=   5.3s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=50, pca__n_components=500; total time=   5.4s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=50, pca__n_components=100; total time=   1.9s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=50, pca__n_components=100; total time=   1.9s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=50, pca__n_components=100; total time=   2.1s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=100, pca__n_components=2000; total time=  30.9s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=100, pca__n_components=2000; total time=  38.5s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=100, pca__n_components=2000; total time=  31.3s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=100, pca__n_components=1000; total time=  14.4s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=100, pca__n_components=1000; total time=  14.6s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=100, pca__n_components=1000; total time=  14.6s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=100, pca__n_components=500; total time=   7.0s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=100, pca__n_components=500; total time=   7.2s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=100, pca__n_components=500; total time=   7.0s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=100, pca__n_components=100; total time=   2.1s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=100, pca__n_components=100; total time=   2.1s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=100, pca__n_components=100; total time=   2.0s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=200, pca__n_components=2000; total time=  44.9s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=200, pca__n_components=2000; total time=  44.8s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=200, pca__n_components=2000; total time=  45.0s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=200, pca__n_components=1000; total time=  21.1s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=200, pca__n_components=1000; total time=  21.5s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=200, pca__n_components=1000; total time=  21.9s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=200, pca__n_components=500; total time=  10.5s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=200, pca__n_components=500; total time=  10.5s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=200, pca__n_components=500; total time=  10.4s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=200, pca__n_components=100; total time=   2.5s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=200, pca__n_components=100; total time=   2.5s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=200, pca__n_components=100; total time=   2.5s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=300, pca__n_components=2000; total time= 1.0min\n","[CV] END classifier__max_depth=5, classifier__n_estimators=300, pca__n_components=2000; total time=  59.5s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=300, pca__n_components=2000; total time=  59.3s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=300, pca__n_components=1000; total time=  28.3s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=300, pca__n_components=1000; total time=  28.7s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=300, pca__n_components=1000; total time=  35.7s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=300, pca__n_components=500; total time=  16.1s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=300, pca__n_components=500; total time=  13.6s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=300, pca__n_components=500; total time=  13.6s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=300, pca__n_components=100; total time=   2.9s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=300, pca__n_components=100; total time=   3.0s\n","[CV] END classifier__max_depth=5, classifier__n_estimators=300, pca__n_components=100; total time=   2.9s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=50, pca__n_components=2000; total time=  27.1s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=50, pca__n_components=2000; total time=  27.8s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=50, pca__n_components=2000; total time=  28.1s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=50, pca__n_components=1000; total time=  12.8s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=50, pca__n_components=1000; total time=  12.9s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=50, pca__n_components=1000; total time=  13.7s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=50, pca__n_components=500; total time=   6.3s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=50, pca__n_components=500; total time=   6.3s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=50, pca__n_components=500; total time=   6.3s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=50, pca__n_components=100; total time=   2.0s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=50, pca__n_components=100; total time=   2.0s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=50, pca__n_components=100; total time=   2.0s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=100, pca__n_components=2000; total time=  37.8s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=100, pca__n_components=2000; total time=  37.6s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=100, pca__n_components=2000; total time=  37.9s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=100, pca__n_components=1000; total time=  18.0s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=100, pca__n_components=1000; total time=  18.2s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=100, pca__n_components=1000; total time=  18.0s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=100, pca__n_components=500; total time=   8.5s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=100, pca__n_components=500; total time=   8.7s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=100, pca__n_components=500; total time=   8.7s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=100, pca__n_components=100; total time=   2.3s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=100, pca__n_components=100; total time=   2.3s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=100, pca__n_components=100; total time=   2.4s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=200, pca__n_components=2000; total time=  57.7s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=200, pca__n_components=2000; total time=  57.9s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=200, pca__n_components=2000; total time= 1.0min\n","[CV] END classifier__max_depth=6, classifier__n_estimators=200, pca__n_components=1000; total time=  27.8s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=200, pca__n_components=1000; total time=  28.8s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=200, pca__n_components=1000; total time=  28.4s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=200, pca__n_components=500; total time=  13.8s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=200, pca__n_components=500; total time=  13.4s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=200, pca__n_components=500; total time=  13.7s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=200, pca__n_components=100; total time=   2.9s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=200, pca__n_components=100; total time=   3.1s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=200, pca__n_components=100; total time=   3.0s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=300, pca__n_components=2000; total time= 1.3min\n","[CV] END classifier__max_depth=6, classifier__n_estimators=300, pca__n_components=2000; total time= 1.3min\n","[CV] END classifier__max_depth=6, classifier__n_estimators=300, pca__n_components=2000; total time= 1.3min\n","[CV] END classifier__max_depth=6, classifier__n_estimators=300, pca__n_components=1000; total time=  38.9s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=300, pca__n_components=1000; total time=  37.7s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=300, pca__n_components=1000; total time=  37.7s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=300, pca__n_components=500; total time=  18.8s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=300, pca__n_components=500; total time=  18.2s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=300, pca__n_components=500; total time=  18.2s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=300, pca__n_components=100; total time=   3.7s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=300, pca__n_components=100; total time=   3.6s\n","[CV] END classifier__max_depth=6, classifier__n_estimators=300, pca__n_components=100; total time=   3.7s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=50, pca__n_components=2000; total time=  34.1s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=50, pca__n_components=2000; total time=  48.0s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=50, pca__n_components=2000; total time=  41.5s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=50, pca__n_components=1000; total time=  18.8s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=50, pca__n_components=1000; total time=  18.8s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=50, pca__n_components=1000; total time=  18.8s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=50, pca__n_components=500; total time=  10.2s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=50, pca__n_components=500; total time=   9.9s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=50, pca__n_components=500; total time=   9.6s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=50, pca__n_components=100; total time=   2.5s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=50, pca__n_components=100; total time=   2.9s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=50, pca__n_components=100; total time=   2.8s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=100, pca__n_components=2000; total time=  49.0s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=100, pca__n_components=2000; total time=  47.8s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=100, pca__n_components=2000; total time=  49.2s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=100, pca__n_components=1000; total time=  22.6s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=100, pca__n_components=1000; total time=  23.2s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=100, pca__n_components=1000; total time=  23.3s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=100, pca__n_components=500; total time=  11.1s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=100, pca__n_components=500; total time=  11.2s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=100, pca__n_components=500; total time=  11.2s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=100, pca__n_components=100; total time=   2.9s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=100, pca__n_components=100; total time=   2.9s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=100, pca__n_components=100; total time=   2.8s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=200, pca__n_components=2000; total time= 1.2min\n","[CV] END classifier__max_depth=7, classifier__n_estimators=200, pca__n_components=2000; total time= 1.3min\n","[CV] END classifier__max_depth=7, classifier__n_estimators=200, pca__n_components=2000; total time= 1.4min\n","[CV] END classifier__max_depth=7, classifier__n_estimators=200, pca__n_components=1000; total time=  36.2s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=200, pca__n_components=1000; total time=  35.9s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=200, pca__n_components=1000; total time=  36.0s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=200, pca__n_components=500; total time=  17.3s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=200, pca__n_components=500; total time=  17.8s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=200, pca__n_components=500; total time=  17.9s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=200, pca__n_components=100; total time=   5.2s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=200, pca__n_components=100; total time=   3.8s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=200, pca__n_components=100; total time=   3.8s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=300, pca__n_components=2000; total time= 1.6min\n","[CV] END classifier__max_depth=7, classifier__n_estimators=300, pca__n_components=2000; total time= 1.6min\n","[CV] END classifier__max_depth=7, classifier__n_estimators=300, pca__n_components=2000; total time= 1.6min\n","[CV] END classifier__max_depth=7, classifier__n_estimators=300, pca__n_components=1000; total time=  46.4s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=300, pca__n_components=1000; total time=  50.9s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=300, pca__n_components=1000; total time=  48.7s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=300, pca__n_components=500; total time=  22.8s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=300, pca__n_components=500; total time=  22.6s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=300, pca__n_components=500; total time=  24.9s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=300, pca__n_components=100; total time=   4.6s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=300, pca__n_components=100; total time=   4.4s\n","[CV] END classifier__max_depth=7, classifier__n_estimators=300, pca__n_components=100; total time=   4.7s\n","Best parameters: {'classifier__max_depth': 5, 'classifier__n_estimators': 300, 'pca__n_components': 1000}\n","Best cross-validation macro F1 score: 0.63\n"]},{"ename":"ValueError","evalue":"Classification metrics can't handle a mix of continuous-multioutput and binary targets","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[16], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m     35\u001b[0m predictions \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict(df_feature_test_scaled)\n\u001b[1;32m---> 36\u001b[0m test_macro_f1 \u001b[38;5;241m=\u001b[39m \u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_feature_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmacro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest macro F1 score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_macro_f1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[1;32mc:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1279\u001b[0m, in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m   1100\u001b[0m     {\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1127\u001b[0m ):\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[0;32m   1129\u001b[0m \n\u001b[0;32m   1130\u001b[0m \u001b[38;5;124;03m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1277\u001b[0m \u001b[38;5;124;03m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[0;32m   1278\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfbeta_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1280\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1281\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471\u001b[0m, in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m   1292\u001b[0m     {\n\u001b[0;32m   1293\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1320\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1321\u001b[0m ):\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[0;32m   1323\u001b[0m \n\u001b[0;32m   1324\u001b[0m \u001b[38;5;124;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;124;03m    0.12...\u001b[39;00m\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1471\u001b[0m     _, _, f, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1472\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1473\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1474\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1477\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf-score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1479\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1481\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\n","File \u001b[1;32mc:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1775\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1612\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[0;32m   1613\u001b[0m \n\u001b[0;32m   1614\u001b[0m \u001b[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;124;03m array([2, 2, 2]))\u001b[39;00m\n\u001b[0;32m   1773\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m _check_zero_division(zero_division)\n\u001b[1;32m-> 1775\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1777\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1778\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n","File \u001b[1;32mc:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1547\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m average_options \u001b[38;5;129;01mand\u001b[39;00m average \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1545\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage has to be one of \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(average_options))\n\u001b[1;32m-> 1547\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1548\u001b[0m \u001b[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[0;32m   1550\u001b[0m present_labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\u001b[38;5;241m.\u001b[39mtolist()\n","File \u001b[1;32mc:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:108\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    105\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    110\u001b[0m             type_true, type_pred\n\u001b[0;32m    111\u001b[0m         )\n\u001b[0;32m    112\u001b[0m     )\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    115\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n","\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous-multioutput and binary targets"]}],"source":["import xgboost as xgb\n","from sklearn.model_selection import GridSearchCV, train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, make_scorer\n","from sklearn.decomposition import PCA\n","from sklearn.pipeline import Pipeline\n","\n","# Create a pipeline with PCA and XGBoost\n","pipeline = Pipeline([\n","    ('pca', PCA()), \n","    ('classifier', xgb.XGBClassifier(objective='binary:logistic', learning_rate=0.1))\n","])\n","\n","# Create a parameter grid\n","param_grid = {\n","    'pca__n_components': [2000, 1000, 500, 100],  # PCA components\n","    'classifier__n_estimators': [50, 100, 200, 300],\n","    'classifier__max_depth': [3, 4, 5, 6, 7]\n","}\n","\n","# Define a scorer for F1 score\n","macro_f1_scorer = make_scorer(f1_score, average='macro')\n","\n","# Create a GridSearchCV object\n","grid_search = GridSearchCV(pipeline, param_grid, scoring=macro_f1_scorer, cv=3, verbose=2)\n","\n","# Fit the grid search to the data\n","grid_search.fit(df_feature_train_scaled, df_target_train)\n","\n","# Print the best parameters and best score\n","print(\"Best parameters:\", grid_search.best_params_)\n","print(\"Best cross-validation macro F1 score: {:.2f}\".format(grid_search.best_score_))\n","\n","# Evaluate the best model on the test set\n","best_model = grid_search.best_estimator_\n","predictions = best_model.predict(df_feature_test_scaled)\n","test_macro_f1 = f1_score(df_target_test, predictions, average='macro')\n","print(f\"Test macro F1 score: {test_macro_f1:.2f}\")"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'classifier__max_depth': 5, 'classifier__n_estimators': 300, 'pca__n_components': 1000}\n"]}],"source":["# Evaluate the best model on the test set\n","best_model = grid_search.best_estimator_\n","predictions = best_model.predict(df_feature_test_scaled)\n","print(grid_search.best_params_)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Test macro F1 score: 0.64\n"]}],"source":["test_macro_f1 = f1_score(df_target_test, predictions, average='macro')\n","print(f\"Test macro F1 score: {test_macro_f1:.2f}\")"]},{"cell_type":"markdown","metadata":{},"source":["max_depth = 5\n","n_estimators = 300\n","pca, n_components = 1000\n","\n","macro f1 score = 0.64"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"data":{"text/plain":["array([0, 0, 1, ..., 1, 1, 0])"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["df_test = pd.read_csv('./data/test_tfidf_features.csv')\n","df_test.drop('id', axis=1, inplace=True)\n","df_test_scaled = scalar.transform(df_test)\n","# pca = PCA(n_components=1000)\n","# df_test_pca = pca.fit_transform(df_test_scaled)\n","pred = best_model.predict(df_test_scaled)\n","pred\n"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["predictions_df = pd.DataFrame(pred, columns=['label'])\n","test_id = pd.read_csv('./data/test_tfidf_features.csv')['id']\n","submission_df = pd.concat([test_id, predictions_df], axis=1)\n","submission_df.to_csv('submission.csv', index=False)"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 3 folds for each of 12 candidates, totalling 36 fits\n","[CV] END ....classifier__max_depth=4, pca__n_components=2000; total time=  54.4s\n","[CV] END ....classifier__max_depth=4, pca__n_components=2000; total time=  50.4s\n","[CV] END ....classifier__max_depth=4, pca__n_components=2000; total time=  54.7s\n","[CV] END ....classifier__max_depth=4, pca__n_components=1000; total time=  34.3s\n","[CV] END ....classifier__max_depth=4, pca__n_components=1000; total time=  22.9s\n","[CV] END ....classifier__max_depth=4, pca__n_components=1000; total time=  22.6s\n","[CV] END .....classifier__max_depth=4, pca__n_components=500; total time=  12.7s\n","[CV] END .....classifier__max_depth=4, pca__n_components=500; total time=  12.6s\n","[CV] END .....classifier__max_depth=4, pca__n_components=500; total time=  12.9s\n","[CV] END .....classifier__max_depth=4, pca__n_components=100; total time=   3.2s\n","[CV] END .....classifier__max_depth=4, pca__n_components=100; total time=   2.4s\n","[CV] END .....classifier__max_depth=4, pca__n_components=100; total time=   2.6s\n","[CV] END ....classifier__max_depth=5, pca__n_components=2000; total time= 1.1min\n","[CV] END ....classifier__max_depth=5, pca__n_components=2000; total time= 1.0min\n","[CV] END ....classifier__max_depth=5, pca__n_components=2000; total time= 1.1min\n","[CV] END ....classifier__max_depth=5, pca__n_components=1000; total time=  43.1s\n","[CV] END ....classifier__max_depth=5, pca__n_components=1000; total time=  38.0s\n","[CV] END ....classifier__max_depth=5, pca__n_components=1000; total time=  35.7s\n","[CV] END .....classifier__max_depth=5, pca__n_components=500; total time=  19.7s\n","[CV] END .....classifier__max_depth=5, pca__n_components=500; total time=  19.7s\n","[CV] END .....classifier__max_depth=5, pca__n_components=500; total time=  23.3s\n","[CV] END .....classifier__max_depth=5, pca__n_components=100; total time=   4.3s\n","[CV] END .....classifier__max_depth=5, pca__n_components=100; total time=   4.7s\n","[CV] END .....classifier__max_depth=5, pca__n_components=100; total time=   4.7s\n","[CV] END ....classifier__max_depth=6, pca__n_components=2000; total time= 1.8min\n","[CV] END ....classifier__max_depth=6, pca__n_components=2000; total time= 1.4min\n","[CV] END ....classifier__max_depth=6, pca__n_components=2000; total time= 1.3min\n","[CV] END ....classifier__max_depth=6, pca__n_components=1000; total time=  38.9s\n","[CV] END ....classifier__max_depth=6, pca__n_components=1000; total time=  38.1s\n","[CV] END ....classifier__max_depth=6, pca__n_components=1000; total time=  37.7s\n","[CV] END .....classifier__max_depth=6, pca__n_components=500; total time=  19.5s\n","[CV] END .....classifier__max_depth=6, pca__n_components=500; total time=  22.0s\n","[CV] END .....classifier__max_depth=6, pca__n_components=500; total time=  19.6s\n","[CV] END .....classifier__max_depth=6, pca__n_components=100; total time=   3.4s\n","[CV] END .....classifier__max_depth=6, pca__n_components=100; total time=   3.3s\n","[CV] END .....classifier__max_depth=6, pca__n_components=100; total time=   3.4s\n","Best parameters: {'classifier__max_depth': 4, 'pca__n_components': 1000}\n","Best cross-validation macro F1 score: 0.63\n","Test macro F1 score: 0.65\n"]}],"source":["import xgboost as xgb\n","from sklearn.model_selection import GridSearchCV, train_test_split\n","from sklearn.metrics import f1_score, make_scorer\n","from sklearn.decomposition import PCA\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","import pandas as pd\n","import numpy as np\n","\n","# Define the functions\n","def prepare_feature(df_feature):\n","    if isinstance(df_feature, pd.DataFrame):\n","        np_feature = df_feature.to_numpy()\n","    else:\n","        np_feature = df_feature\n","    X = np.hstack((np.ones((np_feature.shape[0], 1)), np_feature))\n","    return X\n","\n","def prepare_target(df_target):\n","    if isinstance(df_target, pd.DataFrame):\n","        np_target = df_target.to_numpy()\n","    else:\n","        np_target = df_target\n","    return np_target.ravel()\n","\n","# Ensure split_data function is defined and returns correct splits\n","def split_data(X, y, test_size=0.3, random_state=42):\n","    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n","\n","# Assuming df_feature and df_target are already defined\n","# Prepare features and targets\n","prepared_features = prepare_feature(df_feature)\n","prepared_target = prepare_target(df_target)\n","\n","# Split the data\n","df_feature_train, df_feature_test, df_target_train, df_target_test = split_data(prepared_features, prepared_target, random_state=42, test_size=0.3)\n","\n","# Standardize the data\n","scaler = StandardScaler()\n","df_feature_train_scaled = scaler.fit_transform(df_feature_train)\n","df_feature_test_scaled = scaler.transform(df_feature_test)\n","\n","# Define the pipeline\n","pipeline = Pipeline([\n","    ('pca', PCA()), \n","    ('classifier', xgb.XGBClassifier(objective='binary:logistic', learning_rate=0.1, n_estimators=300))\n","])\n","\n","# Create a parameter grid\n","param_grid = {\n","    'pca__n_components': [2000, 1000, 500, 100],  # Adjust based on your feature size\n","    'classifier__max_depth': [4, 5, 6]\n","}\n","\n","# Define a scorer for F1 score\n","macro_f1_scorer = make_scorer(f1_score, average='macro')\n","\n","# Create a GridSearchCV object\n","grid_search = GridSearchCV(pipeline, param_grid, scoring=macro_f1_scorer, cv=3, verbose=2)\n","\n","# Fit the grid search to the data\n","grid_search.fit(df_feature_train_scaled, df_target_train)\n","\n","# Print the best parameters and best score\n","print(\"Best parameters:\", grid_search.best_params_)\n","print(\"Best cross-validation macro F1 score: {:.2f}\".format(grid_search.best_score_))\n","\n","# Evaluate the best model on the test set\n","best_model = grid_search.best_estimator_\n","predictions = best_model.predict(df_feature_test_scaled)\n","test_macro_f1 = f1_score(df_target_test, predictions, average='macro')\n","print(f\"Test macro F1 score: {test_macro_f1:.2f}\")"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["df_test = pd.read_csv('./data/test_tfidf_features.csv')\n","df_test.drop('id', axis=1, inplace=True)\n","df_test_prepared = prepare_feature(df_test)\n","\n","# Remove the bias term before scaling (if necessary)\n","# df_test_prepared_wo_bias = df_test_prepared[:, 1:]\n","\n","# Use the same scaler and PCA fitted on the training data\n","df_test_scaled = scaler.transform(df_test_prepared)"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"data":{"text/plain":["array([0, 0, 1, ..., 1, 0, 0])"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["pred = best_model.predict(df_test_scaled)\n","pred"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["predictions_df = pd.DataFrame(pred, columns=['label'])\n","test_id = pd.read_csv('./data/test_tfidf_features.csv')['id']\n","submission_df = pd.concat([test_id, predictions_df], axis=1)\n","submission_df.to_csv('submission.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["---"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting imblearn\n","  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n","Collecting imbalanced-learn (from imblearn)\n","  Downloading imbalanced_learn-0.12.3-py3-none-any.whl.metadata (8.3 kB)\n","Requirement already satisfied: numpy>=1.17.3 in c:\\users\\banno\\onedrive - singapore university of technology and design\\desktop\\machine_learning_1d\\.venv\\lib\\site-packages (from imbalanced-learn->imblearn) (2.0.0)\n","Requirement already satisfied: scipy>=1.5.0 in c:\\users\\banno\\onedrive - singapore university of technology and design\\desktop\\machine_learning_1d\\.venv\\lib\\site-packages (from imbalanced-learn->imblearn) (1.14.0)\n","Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\banno\\onedrive - singapore university of technology and design\\desktop\\machine_learning_1d\\.venv\\lib\\site-packages (from imbalanced-learn->imblearn) (1.5.0)\n","Requirement already satisfied: joblib>=1.1.1 in c:\\users\\banno\\onedrive - singapore university of technology and design\\desktop\\machine_learning_1d\\.venv\\lib\\site-packages (from imbalanced-learn->imblearn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\banno\\onedrive - singapore university of technology and design\\desktop\\machine_learning_1d\\.venv\\lib\\site-packages (from imbalanced-learn->imblearn) (3.5.0)\n","Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n","Downloading imbalanced_learn-0.12.3-py3-none-any.whl (258 kB)\n","   ---------------------------------------- 0.0/258.3 kB ? eta -:--:--\n","   ---------------------------------------  256.0/258.3 kB 7.9 MB/s eta 0:00:01\n","   ---------------------------------------- 258.3/258.3 kB 5.4 MB/s eta 0:00:00\n","Installing collected packages: imbalanced-learn, imblearn\n","Successfully installed imbalanced-learn-0.12.3 imblearn-0.0\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 24.1.1 -> 24.1.2\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["!pip install imblearn"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 3 folds for each of 2160 candidates, totalling 6480 fits\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[5], line 69\u001b[0m\n\u001b[0;32m     66\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeline, param_grid, scoring\u001b[38;5;241m=\u001b[39mmacro_f1_scorer, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Fit the grid search to the data\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_feature_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_target_train_res\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Print the best parameters and best score\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n","File \u001b[1;32mc:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:968\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    962\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    963\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    964\u001b[0m     )\n\u001b[0;32m    966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 968\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    972\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[1;32mc:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1543\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1542\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1543\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:914\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    908\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    909\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    910\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    911\u001b[0m         )\n\u001b[0;32m    912\u001b[0m     )\n\u001b[1;32m--> 914\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    934\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    935\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import xgboost as xgb\n","from sklearn.model_selection import GridSearchCV, train_test_split\n","from sklearn.metrics import f1_score, make_scorer, classification_report\n","from sklearn.decomposition import PCA\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler\n","import pandas as pd\n","import numpy as np\n","from imblearn.over_sampling import SMOTE\n","\n","# Define the functions\n","def prepare_feature(df_feature):\n","    if isinstance(df_feature, pd.DataFrame):\n","        np_feature = df_feature.to_numpy()\n","    else:\n","        np_feature = df_feature\n","    return np_feature\n","\n","def prepare_target(df_target):\n","    if isinstance(df_target, pd.DataFrame):\n","        np_target = df_target.to_numpy()\n","    else:\n","        np_target = df_target\n","    return np_target.ravel()\n","\n","def split_data(X, y, test_size=0.3, random_state=42):\n","    return train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n","\n","# Assuming df_feature and df_target are already defined\n","# Prepare features and targets\n","prepared_features = prepare_feature(df_feature)\n","prepared_target = prepare_target(df_target)\n","\n","# Split the data\n","df_feature_train, df_feature_test, df_target_train, df_target_test = split_data(prepared_features, prepared_target, random_state=42, test_size=0.3)\n","\n","# Handle class imbalance with SMOTE\n","smote = SMOTE(random_state=42)\n","df_feature_train_res, df_target_train_res = smote.fit_resample(df_feature_train, df_target_train)\n","\n","# Standardize the data\n","scaler = StandardScaler()\n","df_feature_train_scaled = scaler.fit_transform(df_feature_train_res)\n","df_feature_test_scaled = scaler.transform(df_feature_test)\n","\n","# Define the pipeline\n","pipeline = Pipeline([\n","    ('pca', PCA()), \n","    ('classifier', xgb.XGBClassifier(objective='binary:logistic', learning_rate=0.1))  # Default values\n","])\n","\n","# Create a parameter grid\n","param_grid = {\n","    'pca__n_components': [2000, 1000, 500, 100],  # Adjust based on your feature size\n","    'classifier__n_estimators': [100, 200, 300, 400],\n","    'classifier__max_depth': [4, 5, 6, 7, 8],\n","    'classifier__learning_rate': [0.01, 0.1, 0.2],\n","    'classifier__subsample': [0.8, 0.9, 1.0],\n","    'classifier__colsample_bytree': [0.8, 0.9, 1.0]\n","}\n","\n","# Define a scorer for F1 score\n","macro_f1_scorer = make_scorer(f1_score, average='macro')\n","\n","# Create a GridSearchCV object\n","grid_search = GridSearchCV(pipeline, param_grid, scoring=macro_f1_scorer, cv=3, verbose=2, n_jobs=-1)\n","\n","# Fit the grid search to the data\n","grid_search.fit(df_feature_train_scaled, df_target_train_res)\n","\n","# Print the best parameters and best score\n","print(\"Best parameters:\", grid_search.best_params_)\n","print(\"Best cross-validation macro F1 score: {:.2f}\".format(grid_search.best_score_))\n","\n","# Evaluate the best model on the test set\n","best_model = grid_search.best_estimator_\n","predictions = best_model.predict(df_feature_test_scaled)\n","test_macro_f1 = f1_score(df_target_test, predictions, average='macro')\n","print(f\"Test macro F1 score: {test_macro_f1:.2f}\")\n","\n","# Print a detailed classification report\n","print(classification_report(df_target_test, predictions))"]},{"cell_type":"markdown","metadata":{},"source":["## Support Vector Machine"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\banno\\OneDrive - Singapore University of Technology and Design\\Desktop\\machine_learning_1d\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1310: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.svm import SVC\n","from sklearn.pipeline import Pipeline\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import f1_score, make_scorer, classification_report\n","\n","# Define the functions\n","def prepare_feature(df_feature):\n","    if isinstance(df_feature, pd.DataFrame):\n","        np_feature = df_feature.to_numpy()\n","    else:\n","        np_feature = df_feature\n","    X = np.hstack((np.ones((np_feature.shape[0], 1)), np_feature))\n","    return X\n","\n","def prepare_target(df_target):\n","    if isinstance(df_target, pd.DataFrame):\n","        np_target = df_target.to_numpy()\n","    else:\n","        np_target = df_target\n","    return np_target.ravel()\n","\n","def split_data(df_feature, df_target, random_state=None, test_size=0.5):\n","    indexes = df_feature.index.to_numpy()\n","    if random_state is not None:\n","        np.random.seed(random_state)\n","    test_index = np.random.choice(indexes, int(len(indexes) * test_size), replace=False)\n","    train_index = np.setdiff1d(indexes, test_index)\n","    \n","    df_feature_train = df_feature.loc[train_index, :]\n","    df_feature_test = df_feature.loc[test_index, :]\n","    df_target_train = df_target.loc[train_index, :]\n","    df_target_test = df_target.loc[test_index, :]\n","    \n","    return df_feature_train, df_feature_test, df_target_train, df_target_test\n","\n","# Assuming df_feature and df_target are already defined and preprocessed\n","# df_feature is in TF-IDF format with 5000 features\n","# df_target contains the target labels\n","\n","# Prepare features and targets\n","prepared_features = prepare_feature(df_feature)\n","prepared_target = prepare_target(df_target)\n","\n","# Split the data\n","df_feature_train, df_feature_test, df_target_train, df_target_test = split_data(df_feature, df_target, random_state=42, test_size=0.3)\n","\n","# Standardize the data\n","scaler = StandardScaler(with_mean=False)  # with_mean=False because TF-IDF data is sparse\n","df_feature_train_scaled = scaler.fit_transform(df_feature_train)\n","df_feature_test_scaled = scaler.transform(df_feature_test)\n","\n","# Define the pipeline\n","pipeline = Pipeline([\n","    ('pca', PCA()), \n","    ('classifier', SVC(kernel='linear'))\n","])\n","\n","# Create a parameter grid\n","param_grid = {\n","    'pca__n_components': [2000, 1000, 500, 100],  # Adjust based on your feature size\n","}\n","\n","# Define a scorer for F1 score\n","macro_f1_scorer = make_scorer(f1_score, average='macro')\n","\n","# Create a GridSearchCV object\n","grid_search = GridSearchCV(pipeline, param_grid, scoring=macro_f1_scorer, cv=5, verbose=2)\n","\n","# Fit the grid search to the data\n","grid_search.fit(df_feature_train_scaled, df_target_train)\n","\n","# Print the best parameters and best score\n","print(\"Best parameters:\", grid_search.best_params_)\n","print(\"Best cross-validation macro F1 score: {:.2f}\".format(grid_search.best_score_))\n","\n","# Evaluate the best model on the test set\n","best_model = grid_search.best_estimator_\n","predictions = best_model.predict(df_feature_test_scaled)\n","test_macro_f1 = f1_score(df_target_test, predictions, average='macro')\n","print(f\"Test macro F1 score: {test_macro_f1:.2f}\")\n","\n","# Print a detailed classification report\n","print(classification_report(df_target_test, predictions))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":2}
